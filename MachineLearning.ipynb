{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPM/UwLyFQuz5HSg8V/hpeL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**ASSIGNMENT QUESTIONS**"],"metadata":{"id":"3a47lw3sNOHf"}},{"cell_type":"markdown","source":["1. What is a parameter?\n","- In Machine Learning, a parameter is an internal variable of the model that is learned from the training data. For example, in a linear regression model, the coefficients (weights) of the features are parameters. These values are optimized during the training process to make accurate predictions.\n","\n","2. What is correlation?\n","- Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. A positive correlation means both variables increase together, while a negative correlation means one increases as the other decreases.\n","\n","3. What does negative correlation mean?\n","- Negative correlation means that as one variable increases, the other tends to decrease. For example, if hours of watching TV increases and study time decreases, they have a negative correlation. The correlation coefficient in this case will be less than 0.\n","\n","4. Define Machine Learning. What are the main components in Machine Learning?\n","- Machine Learning is a subset of artificial intelligence that enables machines to learn patterns from data and make decisions without being explicitly programmed.\n","- Main components include:\n","\n","  - Data: The input from which the model learns.\n","\n","  - Features: Variables or attributes used for predictions.\n","\n","  - Model: The algorithmic structure that learns from data.\n","\n","  - Training Process: The method to optimize parameters.\n","\n","   - Loss Function: Measures the model’s error.\n","\n","  - Evaluation Metric: Assesses model performance.\n","\n","5. How does loss value help in determining whether the model is good or not?\n","- The loss value quantifies how well or poorly a machine learning model is performing. It calculates the difference between the predicted values and the actual values. A lower loss indicates better performance, while a higher loss indicates the model needs improvement.\n","\n","6. What are continuous and categorical variables?\n","- Continuous variables are numerical and can take any value within a range (e.g., height, temperature).\n","\n","- Categorical variables represent categories or groups, such as gender, colors, or product types.\n","\n","7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n","- Categorical variables are converted into numerical form before being used in ML models.\n","- Common techniques include:\n","\n","  - Label Encoding: Assigns a unique number to each category.\n","\n","  - One-Hot Encoding: Converts each category into a binary column.\n","\n","  - Ordinal Encoding: Used when categories have a natural order.\n","\n","8. What do you mean by training and testing a dataset?\n","- Training a dataset means feeding the model with data so it can learn patterns. Testing involves evaluating the model’s performance on new, unseen data. The dataset is typically split into a training set and a testing set to validate the model.\n","\n","9. What is sklearn.preprocessing?\n","- sklearn.preprocessing is a module in Scikit-learn used for preparing data before training. It includes functions for scaling, encoding, imputing missing values, and transforming features to a suitable format.\n","\n","10. What is a Test set?\n","- A test set is a portion of the dataset that is kept separate from training data and is used to evaluate the final performance of the trained model. It helps to check if the model generalizes well to unseen data.\n","\n","11. How do we split data for model fitting (training and testing) in Python?\n","- We commonly use the train_test_split() function from Scikit-learn’s model_selection module to divide the dataset into training and testing sets. Typically, 70–80% is used for training and the rest for testing.\n","\n","12. How do you approach a Machine Learning problem?\n","- Understand the problem and collect relevant data.\n","\n","- Clean and preprocess the data (handling missing values, encoding).\n","\n","- Perform exploratory data analysis (EDA).\n","\n","- Select features and choose a suitable model.\n","\n","- Train the model using training data.\n","\n","- Evaluate it using metrics like accuracy, precision, or RMSE.\n","\n","- Tune hyperparameters if needed.\n","\n","- Deploy and monitor the model.\n","\n","13. Why do we have to perform EDA before fitting a model to the data?\n","- Exploratory Data Analysis (EDA) helps understand the data distribution, relationships between variables, missing values, and outliers. It ensures data quality and guides feature selection and model choice, which improves model accuracy and performance.\n","\n","14. What is correlation?\n","- Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. A positive correlation means both variables increase together, while a negative correlation means one increases as the other decreases.\n","\n","15. What does negative correlation mean?\n","- Negative correlation means that as one variable increases, the other tends to decrease. For example, if hours of watching TV increases and study time decreases, they have a negative correlation. The correlation coefficient in this case will be less than 0.\n","\n","16. How can you find correlation between variables in Python?\n","- You can use:\n","\n","  - .corr() method in Pandas to find correlation matrix.\n","\n","  - seaborn.heatmap() to visualize the correlation matrix.\n","\n","  - scipy.stats.pearsonr() to compute Pearson correlation coefficient.\n","\n","17. What is causation? Explain difference between correlation and causation with an example.\n","- Causation means that one variable directly affects another.\n","- Example: More hours of study cause better exam scores.\n","- Correlation may show that ice cream sales and drowning rates are related, but one does not cause the other — it’s due to a third factor like summer weather.\n","\n","18. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n","- An optimizer adjusts the model’s parameters to minimize the loss function during training.\n","- Types:\n","\n","  - SGD (Stochastic Gradient Descent): Updates parameters using one sample at a time.\n","\n","  - Adam: Adaptive learning rate optimizer, works well in most scenarios.\n","\n","  - RMSprop: Good for non-stationary problems and faster convergence.\n","\n","19. What is sklearn.linear_model?\n","- It is a module in Scikit-learn that includes linear models like Linear Regression, Logistic Regression, Ridge, and Lasso. It provides functions for fitting and predicting using linear techniques.\n","\n","20. What does model.fit() do? What arguments must be given?\n","- model.fit() trains the model using training data.\n","- Arguments:\n","\n","  - X: Feature data\n","\n","  - y: Target data\n","    It adjusts model parameters to reduce the error.\n","\n","21. What does model.predict() do? What arguments must be given?\n","- model.predict() uses the trained model to make predictions on new data.\n","- Argument:\n","\n","  - X: New input data (same features as training)\n","\n","22. What are continuous and categorical variables?\n","- Categorical variables represent categories or groups, such as gender, colors, or product types.\n","\n","23. What is feature scaling? How does it help in Machine Learning?\n","- Feature scaling standardizes or normalizes the range of independent variables. It helps algorithms like SVM, kNN, and Gradient Descent converge faster and avoid bias towards higher magnitude features.\n","\n","24. How do we perform scaling in Python?\n","- Use Scikit-learn’s preprocessing tools:\n","\n","- StandardScaler for standardization (mean = 0, std = 1)\n","\n","- MinMaxScaler for normalization (range 0–1)\n","\n","      from sklearn.preprocessing import StandardScaler\n","      scaler = StandardScaler()\n","      X_scaled = scaler.fit_transform(X)\n","25. What is sklearn.preprocessing?\n","- sklearn.preprocessing is a module in Scikit-learn used for preparing data before training. It includes functions for scaling, encoding, imputing missing values, and transforming features to a suitable format.\n","\n","26. How do we split data for model fitting (training and testing) in Python?\n","- We commonly use the train_test_split() function from Scikit-learn’s model_selection module to divide the dataset into training and testing sets. Typically, 70–80% is used for training and the rest for testing.\n","\n","\n","\n","27. Explain data encoding?\n","- Data encoding transforms categorical data into numerical form.\n","- Common methods:\n","\n","  - Label Encoding: Converts categories into integers.\n","\n","  - One-Hot Encoding: Creates binary columns for each category.\n","- It ensures compatibility with machine learning models that require numerical inputs."],"metadata":{"id":"-o1z5_OZLFgr"}}]}